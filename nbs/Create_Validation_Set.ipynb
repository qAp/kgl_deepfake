{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path('../data/')\n",
    "save_path = Path('../val_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos from folder 0->3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annots(folder):\n",
    "    f = get_files(folder, extensions=['.json']) # Extract the metadata\n",
    "    a = pd.read_json(f[0]).T\n",
    "    a.reset_index(inplace=True)\n",
    "    a.rename({'index':'fname'}, axis=1, inplace=True)\n",
    "    a.fname = folder.name + '/' + a.fname.astype(str)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(SOURCE, include=None, exclude=None):\n",
    "    \"\"\"\n",
    "    extract the metadata from all the folders contained in SOURCE.\n",
    "    \"\"\"\n",
    "    meta = []\n",
    "    \n",
    "    for i in SOURCE.iterdir(): # iterate over the files in SOURCE\n",
    "        if i.is_dir() and (i/'metadata.json').is_file(): # Get only the directories\n",
    "            if include is not None and i.name in include: # Check if in include\n",
    "                print(f'Extracting data from the {i.name} folder')\n",
    "                a = get_annots(i)\n",
    "                meta.append(a)\n",
    "            if exclude is not None and i.name not in exclude: # Check if not in exlcude\n",
    "                print(f'Extracting data from the {i.name} folder')\n",
    "                a = get_annots(i)\n",
    "                meta.append(a)\n",
    "    \n",
    "    metadata = pd.concat(meta)\n",
    "    metadata.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from the dfdc_train_part_2 folder\n",
      "Extracting data from the dfdc_train_part_3 folder\n",
      "Extracting data from the dfdc_train_part_0 folder\n",
      "Extracting data from the dfdc_train_part_1 folder\n"
     ]
    }
   ],
   "source": [
    "#train_meta = get_metadata(source_path, exclude=['dfdc_train_part_0', 'dfdc_train_part_1', 'dfdc_train_part_2', 'dfdc_train_part_3'])\n",
    "val_meta = get_metadata(source_path, include=['dfdc_train_part_0', 'dfdc_train_part_1', 'dfdc_train_part_2', 'dfdc_train_part_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dfdc_train_part_2/qyyebirxwe.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>ejhhokmvpe.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfdc_train_part_2/ntjlknlcvn.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>nthpnwylxo.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dfdc_train_part_2/qivpypiwlp.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hszwwswewp.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dfdc_train_part_2/lpkgabskbw.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>rnxzqumvvl.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfdc_train_part_2/vctemjbusz.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>sznkemeqro.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fname label  split        original\n",
       "0  dfdc_train_part_2/qyyebirxwe.mp4  FAKE  train  ejhhokmvpe.mp4\n",
       "1  dfdc_train_part_2/ntjlknlcvn.mp4  FAKE  train  nthpnwylxo.mp4\n",
       "2  dfdc_train_part_2/qivpypiwlp.mp4  FAKE  train  hszwwswewp.mp4\n",
       "3  dfdc_train_part_2/lpkgabskbw.mp4  FAKE  train  rnxzqumvvl.mp4\n",
       "4  dfdc_train_part_2/vctemjbusz.mp4  FAKE  train  sznkemeqro.mp4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def runnit(f):\n",
    "    def _func(*args, **kwargs):\n",
    "        command = f(*args, **kwargs)\n",
    "        p = subprocess.run(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return p\n",
    "    return _func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _ffmpeg_web_defaults():\n",
    "    '''\n",
    "    These are some reasonable values for uploading. i.e. YouTube, etc.\n",
    "    '''\n",
    "    return dict(video_encoder='libx264', video_bitrate='1.5M', fps=30, scale=.5, crf=23, #17-28\n",
    "                audio_encoder='aac', audio_bitrate='128k')\n",
    "\n",
    "def _ffmpeg_defaults():\n",
    "    return dict(video_encoder=None, video_bitrate=None, fps=None, scale=None, crf=None,\n",
    "                audio_encoder=None, audio_bitrate=None)\n",
    "\n",
    "def _ffmpeg_fmts():\n",
    "    \"ffmpeg options syntax\"\n",
    "    return dict(video_encoder='-c:v {video_encoder:s}', \n",
    "                video_bitrate='-b:v {video_bitrate:s}', \n",
    "                fps='-r {fps:d}', \n",
    "                #scale='-vf scale=iw*{scale:.2f}:ih*{scale:.2f}', \n",
    "                scale='-vf scale=iw*{scale:.2f}:-1',\n",
    "                crf='-crf {crf:d}',\n",
    "                audio_bitrate='-b:a {audio_bitrate}', \n",
    "                audio_encoder='-c:a {audio_encoder}')\n",
    "\n",
    "#@show_vid_info\n",
    "@runnit\n",
    "def run_ffmpeg(fpath_from=None, fpath_to=None, **kwargs):\n",
    "    '''\n",
    "    Run ffmpeg\n",
    "    '''\n",
    "    ps = _ffmpeg_defaults()\n",
    "    ps.update(kwargs)\n",
    "    pstr = []\n",
    "    for n, s in _ffmpeg_fmts().items():\n",
    "        if ps[n] is None: pstr.append('')\n",
    "        else: pstr.append(s.format(**ps))\n",
    "    pstr = ' '.join(pstr)\n",
    "    return f'ffmpeg -i {fpath_from} {pstr} {fpath_to}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_degraded_videos(source_path, save_path, fnames):\n",
    "    \n",
    "        for fname in tqdm(fnames):\n",
    "            deg = random.randint(1,3)\n",
    "            \n",
    "            if deg==1:\n",
    "                f = Path(f'{save_path}/{Path(fname).parents[0].name}').mkdir(parents=True, exist_ok=True)\n",
    "                fpath_to = Path(fname).parts[-2]+'/copy_'+ Path(fname).parts[-1]\n",
    "                \n",
    "                !cp {source_path/fname} {save_path/fpath_to}\n",
    "            \n",
    "            else:\n",
    "                f = Path(f'{save_path}/{Path(fname).parents[0].name}').mkdir(parents=True, exist_ok=True)\n",
    "                fpath_to = Path(fname).parts[-2]+'/degraded_'+ Path(fname).parts[-1]\n",
    "                run_ffmpeg(fpath_from=source_path/fname, fpath_to=save_path/fpath_to, crf=28, scale=0.5, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6236/6236 [1:30:13<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "create_degraded_videos(source_path, save_path, val_meta.fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
