{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification using 'video list'"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.0.0-py3-none-any.whl\nfrom facenet_pytorch.models.inception_resnet_v1 import get_torch_home\ntorch_home = get_torch_home()\n# Copy model checkpoints to torch cache so they are loaded automatically by the package\n!mkdir -p $torch_home/checkpoints/\n!cp /kaggle/input/facenet-pytorch-vggface2/20180402-114759-vggface2-logits.pth $torch_home/checkpoints/vggface2_DG3kwML46X.pt\n!cp /kaggle/input/facenet-pytorch-vggface2/20180402-114759-vggface2-features.pth $torch_home/checkpoints/vggface2_G5aNV2VSMn.pt\n! cp ../input/realfake/kernel_module.py ../working/.\nfrom kernel_module import *","execution_count":1,"outputs":[{"output_type":"stream","text":"Processing /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.0.0-py3-none-any.whl\nRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from facenet-pytorch==2.0.0) (2.22.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from facenet-pytorch==2.0.0) (1.17.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (1.24.2)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (2019.9.11)\nInstalling collected packages: facenet-pytorch\nSuccessfully installed facenet-pytorch-2.0.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE = Path('../input/deepfake-detection-challenge/train_sample_videos/')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = get_files(SOURCE, extensions=['.json'])[0]\nannots = pd.read_json(f).T\nannots.reset_index(inplace=True)\nannots.rename({'index':'fname'}, axis=1, inplace=True)\nannots.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"            fname label  split        original\n0  aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n1  aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n2  abarnvbtwb.mp4  REAL  train            None\n3  abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n4  abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n      <th>split</th>\n      <th>original</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aagfhgtpmv.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>vudstovrck.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aapnvogymq.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>jdubbvfswz.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abarnvbtwb.mp4</td>\n      <td>REAL</td>\n      <td>train</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abofeumbvv.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>atvmxvwyns.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abqwwspghj.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>qzimuostzz.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Get face detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector = MTCNN(device=device, post_process=False)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Remove videos in which no faces are detected.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = [SOURCE/o for o in annots.fname]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hasface = get_has_face(fnames, detector)","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='400' class='' max='400', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [400/400 00:42<00:00]\n    </div>\n    "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"annots_hasface = annots[np.array(hasface)]","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create `DataBunch`"},{"metadata":{"trusted":true},"cell_type":"code","source":"src = (VideoFaceList\n       .from_df(df=annots_hasface, path=SOURCE, cols='fname', detector=detector)\n       .split_by_rand_pct())","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs, sz = 32, 128","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (src.label_from_df('label').transform(get_transforms(), size=sz)\n        .databunch(bs=bs, num_workers=0).normalize(imagenet_stats))","execution_count":11,"outputs":[{"output_type":"stream","text":"CPU times: user 4.6 s, sys: 72 ms, total: 4.67 s\nWall time: 3.79 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MesoNet()","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Learner"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(data, model, metrics=accuracy, path='../input/realfake/', model_dir='')","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('mesonet_stage1');","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE_TEST = Path('../input/deepfake-detection-challenge/test_videos/')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = get_files(SOURCE_TEST, extensions=['.mp4'])\nfnames[:3]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"[PosixPath('../input/deepfake-detection-challenge/test_videos/iorbtaarte.mp4'),\n PosixPath('../input/deepfake-detection-challenge/test_videos/vnlzxqwthl.mp4'),\n PosixPath('../input/deepfake-detection-challenge/test_videos/gqnaxievjx.mp4')]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Again, because we can't deal with videos which have no detected face, we need to ignore them for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"hasface_tst = get_has_face(fnames, detector)","execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='400' class='' max='400', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [400/400 00:42<00:00]\n    </div>\n    "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames_tst_hasface = [f for f, b in zip(fnames, hasface_tst) if b]\nlen(fnames_tst_hasface)","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"396"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vlist = VideoFaceList(sorted(fnames_tst_hasface), detector=detector)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(vlist.items), len(vlist)","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(396, 396)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Note that there are 400 test videos, but we will only be able to write an entry in the submission file for 396 of these."},{"metadata":{"trusted":false},"cell_type":"code","source":"! head  ../data/sample_submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = infer_on_videolist(learn, vlist)","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='396' class='' max='396', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [396/396 00:44<00:00]\n    </div>\n    "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"         filename  label\n0  aassnaulhq.mp4      0\n1  aayfryxljh.mp4      0\n2  acazlolrpz.mp4      0\n3  adohdulfwb.mp4      0\n4  ahjnxtiamx.mp4      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aassnaulhq.mp4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aayfryxljh.mp4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>acazlolrpz.mp4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>adohdulfwb.mp4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ahjnxtiamx.mp4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! head submission.csv","execution_count":32,"outputs":[{"output_type":"stream","text":"filename,label\r\naassnaulhq.mp4,0\r\naayfryxljh.mp4,0\r\nacazlolrpz.mp4,0\r\nadohdulfwb.mp4,0\r\nahjnxtiamx.mp4,1\r\najiyrjfyzp.mp4,0\r\naktnlyqpah.mp4,0\r\nalrtntfxtd.mp4,0\r\naomqqjipcp.mp4,1\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# - fin"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}