{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deepfake Submission"},{"metadata":{},"cell_type":"markdown","source":"This notebook is intended to be a submission kernel for the competition. To use it, you need to add the public dataset [facenet_pytorch](https://www.kaggle.com/timesler/facenet-pytorch-vggface2) and one of your own that contains:\n\n1. *kernel_module.py*, containing all the defintions of your own functions and classes.\n2. A *.pth* file for loading your trained model into fastai's `Learner`.  If the file is called *mesonet_stage1.pth*, you need to assign `'mesonet_stage1'` to `FNAME_LEARNER` in this notebook.\n\nIf you own dataset is called *realfake*, you need to assign `'realfake'` to `DIR_MYCODE` in this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_MYCODE = 'realfake'\nFNAME_LEARNER = 'mesonet_stage1'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls ../input/{DIR_MYCODE}/","execution_count":6,"outputs":[{"output_type":"stream","text":"kernel_module.py  mesonet_stage1.pkl  mesonet_stage1.pth\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.0.0-py3-none-any.whl\nfrom facenet_pytorch.models.inception_resnet_v1 import get_torch_home\ntorch_home = get_torch_home()\n# Copy model checkpoints to torch cache so they are loaded automatically by the package\n!mkdir -p $torch_home/checkpoints/\n!cp /kaggle/input/facenet-pytorch-vggface2/20180402-114759-vggface2-logits.pth $torch_home/checkpoints/vggface2_DG3kwML46X.pt\n!cp /kaggle/input/facenet-pytorch-vggface2/20180402-114759-vggface2-features.pth $torch_home/checkpoints/vggface2_G5aNV2VSMn.pt\n! cp ../input/{DIR_MYCODE}/kernel_module.py ../working/.\nfrom kernel_module import *","execution_count":7,"outputs":[{"output_type":"stream","text":"Processing /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.0.0-py3-none-any.whl\nRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from facenet-pytorch==2.0.0) (2.22.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from facenet-pytorch==2.0.0) (1.17.4)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (1.24.2)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->facenet-pytorch==2.0.0) (2019.9.11)\nInstalling collected packages: facenet-pytorch\nSuccessfully installed facenet-pytorch-2.0.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE = Path('../input/deepfake-detection-challenge/train_sample_videos/')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = get_files(SOURCE, extensions=['.json'])[0]\nannots = pd.read_json(f).T\nannots.reset_index(inplace=True)\nannots.rename({'index':'fname'}, axis=1, inplace=True)\nannots.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"            fname label  split        original\n0  aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n1  aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n2  abarnvbtwb.mp4  REAL  train            None\n3  abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n4  abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n      <th>split</th>\n      <th>original</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aagfhgtpmv.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>vudstovrck.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aapnvogymq.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>jdubbvfswz.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abarnvbtwb.mp4</td>\n      <td>REAL</td>\n      <td>train</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abofeumbvv.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>atvmxvwyns.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abqwwspghj.mp4</td>\n      <td>FAKE</td>\n      <td>train</td>\n      <td>qzimuostzz.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Get face detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector = MTCNN(device=device, post_process=False)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Remove videos in which no faces are detected.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = [SOURCE/o for o in annots.fname]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hasface = get_has_face(fnames, detector)","execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='400' class='' max='400', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [400/400 00:41<00:00]\n    </div>\n    "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"annots_hasface = annots[np.array(hasface)]","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create `DataBunch`"},{"metadata":{"trusted":true},"cell_type":"code","source":"src = (VideoFaceList\n       .from_df(df=annots_hasface, path=SOURCE, cols='fname', detector=detector)\n       .split_by_rand_pct())","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs, sz = 32, 128","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (src.label_from_df('label').transform(get_transforms(), size=sz)\n        .databunch(bs=bs, num_workers=0).normalize(imagenet_stats))","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MesoNet()","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Learner"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(data, model, metrics=accuracy, path=f'../input/{DIR_MYCODE}/', model_dir='')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load(FNAME_LEARNER);","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE_TEST = Path('../input/deepfake-detection-challenge/test_videos/')","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = get_files(SOURCE_TEST, extensions=['.mp4'])\nfnames[:3]","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"[PosixPath('../input/deepfake-detection-challenge/test_videos/iorbtaarte.mp4'),\n PosixPath('../input/deepfake-detection-challenge/test_videos/vnlzxqwthl.mp4'),\n PosixPath('../input/deepfake-detection-challenge/test_videos/gqnaxievjx.mp4')]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Again, because we can't deal with videos which have no detected face, we need to first separate these."},{"metadata":{"trusted":true},"cell_type":"code","source":"hasface_tst = get_has_face(fnames, detector)","execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='400' class='' max='400', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [400/400 00:40<00:00]\n    </div>\n    "},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames_tst_hasface = [f for f, b in zip(fnames, hasface_tst) if b]\nlen(fnames_tst_hasface)","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"396"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Infer on videos in which a face can be detected."},{"metadata":{"trusted":true},"cell_type":"code","source":"vlist = VideoFaceList(sorted(fnames_tst_hasface), detector=detector)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = infer_on_videolist(learn, vlist)","execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='396' class='' max='396', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [396/396 00:42<00:00]\n    </div>\n    "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Then, fill in dummy labels for those in which a face *cannot* be detected. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def insert_noface_entries(df, fnames, hasface):\n    label_fill = 0  # Fill in 'FAKE'.\n    assert len(fnames) == len(hasface)\n    fnames_noface = [f for f, b in zip(fnames, hasface) if not b]\n    for o in fnames_noface:\n        df = df.append(pd.Series([o.name, label_fill], index=df.columns), ignore_index=True)\n    df.sort_values('filename', axis=0, inplace=True)\n    return df.reset_index()","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = insert_noface_entries(df, fnames, hasface_tst)","execution_count":63,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write out the *submission.csv* file."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":67,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# - fin"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}