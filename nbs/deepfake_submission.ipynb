{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deepfake Submission"},{"metadata":{},"cell_type":"markdown","source":"This notebook is intended to be a submission kernel for the competition. To use it, you need to add the public dataset [facenet_pytorch](https://www.kaggle.com/timesler/facenet-pytorch-vggface2) and one of your own that contains:\n\n1. *kernel_module.py*, containing all the defintions of your own functions and classes.\n2. A *.pth* file for loading your trained model into fastai's `Learner`.  If the file is called *mesonet_stage1.pth*, you need to assign `'mesonet_stage1'` to `FNAME_LEARNER` in this notebook.\n\nIf you own dataset is called *realfake*, you need to assign `'realfake'` to `DIR_MYCODE` in this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_MYCODE = 'realfake'\nFNAME_LEARNER = 'mesonet_stage1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls ../input/{DIR_MYCODE}/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/facenet-pytorch-vggface2/facenet_pytorch-2.0.0-py3-none-any.whl\nfrom facenet_pytorch.models.inception_resnet_v1 import get_torch_home\ntorch_home = get_torch_home()\n# Copy model checkpoints to torch cache so they are loaded automatically by the package\n!mkdir -p $torch_home/checkpoints/\n!cp /kaggle/input/facenet-pytorch-vggface2/20180402-114759-vggface2-logits.pth $torch_home/checkpoints/vggface2_DG3kwML46X.pt\n!cp /kaggle/input/facenet-pytorch-vggface2/20180402-114759-vggface2-features.pth $torch_home/checkpoints/vggface2_G5aNV2VSMn.pt\n! cp ../input/{DIR_MYCODE}/kernel_module.py ../working/.\nfrom kernel_module import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE = Path('../input/deepfake-detection-challenge/train_sample_videos/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = get_files(SOURCE, extensions=['.json'])[0]\nannots = pd.read_json(f).T\nannots.reset_index(inplace=True)\nannots.rename({'index':'fname'}, axis=1, inplace=True)\nannots.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Get face detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector = MTCNN(device=device, post_process=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Remove videos in which no faces are detected.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = [SOURCE/o for o in annots.fname]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hasface = get_has_face(fnames, detector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annots_hasface = annots[np.array(hasface)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create `DataBunch`"},{"metadata":{"trusted":true},"cell_type":"code","source":"src = (VideoFaceList\n       .from_df(df=annots_hasface, path=SOURCE, cols='fname', detector=detector)\n       .split_by_rand_pct())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs, sz = 32, 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (src.label_from_df('label').transform(get_transforms(), size=sz)\n        .databunch(bs=bs, num_workers=0).normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MesoNet()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Learner"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(data, model, metrics=accuracy, path=f'../input/{DIR_MYCODE}/', model_dir='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load(FNAME_LEARNER);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE_TEST = Path('../input/deepfake-detection-challenge/test_videos/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = get_files(SOURCE_TEST, extensions=['.mp4'])\nfnames[:3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, because we can't deal with videos which have no detected face, we need to first separate these."},{"metadata":{"trusted":true},"cell_type":"code","source":"hasface_tst = get_has_face(fnames, detector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames_tst_hasface = [f for f, b in zip(fnames, hasface_tst) if b]\nlen(fnames_tst_hasface)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Infer on videos in which a face can be detected."},{"metadata":{"trusted":true},"cell_type":"code","source":"vlist = VideoFaceList(sorted(fnames_tst_hasface), detector=detector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_hasface = infer_on_videolist(learn, vlist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, fill in dummy labels for those in which a face *cannot* be detected. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def insert_noface_entries(df, fnames, hasface):\n    label_fill = 0  # Fill in 'FAKE'.\n    assert len(fnames) == len(hasface)\n    fnames_noface = [f for f, b in zip(fnames, hasface) if not b]\n    for o in fnames_noface:\n        df = df.append(pd.Series([o.name, label_fill], index=df.columns), ignore_index=True)\n    df.sort_values('filename', axis=0, inplace=True)\n    return df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = insert_noface_entries(df_hasface, fnames, hasface_tst)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write out the *submission.csv* file."},{"metadata":{},"cell_type":"markdown","source":"**Write out a trivial *submission.csv***"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = pd.DataFrame([(o.name, 0) for o in fnames], columns=['filename', 'label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# - fin"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}