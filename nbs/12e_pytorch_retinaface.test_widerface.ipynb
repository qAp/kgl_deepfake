{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pytorch_retinaface.test_widerface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# %load Pytorch_Retinaface/test_widerface.py\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from kgl_deepfake.pytorch_retinaface.data import cfg_mnet, cfg_re50\n",
    "from kgl_deepfake.pytorch_retinaface.layers.functions.prior_box import PriorBox\n",
    "from kgl_deepfake.pytorch_retinaface.utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from kgl_deepfake.pytorch_retinaface.models.retinaface import RetinaFace\n",
    "from kgl_deepfake.pytorch_retinaface.utils.box_utils import decode, decode_landm\n",
    "from kgl_deepfake.pytorch_retinaface.utils.timer import Timer\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Retinaface')\n",
    "# parser.add_argument('-m', '--trained_model', default='./weights/Resnet50_Final.pth',\n",
    "#                     type=str, help='Trained state_dict file path to open')\n",
    "# parser.add_argument('--network', default='resnet50', help='Backbone network mobile0.25 or resnet50')\n",
    "# parser.add_argument('--origin_size', default=True, type=str, help='Whether use origin image size to evaluate')\n",
    "# parser.add_argument('--save_folder', default='./widerface_evaluate/widerface_txt/', type=str, help='Dir to save txt results')\n",
    "# parser.add_argument('--cpu', action=\"store_true\", default=False, help='Use cpu inference')\n",
    "# parser.add_argument('--dataset_folder', default='./data/widerface/val/images/', type=str, help='dataset path')\n",
    "# parser.add_argument('--confidence_threshold', default=0.02, type=float, help='confidence_threshold')\n",
    "# parser.add_argument('--top_k', default=5000, type=int, help='top_k')\n",
    "# parser.add_argument('--nms_threshold', default=0.4, type=float, help='nms_threshold')\n",
    "# parser.add_argument('--keep_top_k', default=750, type=int, help='keep_top_k')\n",
    "# parser.add_argument('-s', '--save_image', action=\"store_true\", default=False, help='show detection results')\n",
    "# parser.add_argument('--vis_thres', default=0.5, type=float, help='visualization_threshold')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    cfg = None\n",
    "    if args.network == \"mobile0.25\":\n",
    "        cfg = cfg_mnet\n",
    "    elif args.network == \"resnet50\":\n",
    "        cfg = cfg_re50\n",
    "    # net and model\n",
    "    net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "    net = load_model(net, args.trained_model, args.cpu)\n",
    "    net.eval()\n",
    "    print('Finished loading model!')\n",
    "    print(net)\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device(\"cpu\" if args.cpu else \"cuda\")\n",
    "    net = net.to(device)\n",
    "\n",
    "    # testing dataset\n",
    "    testset_folder = args.dataset_folder\n",
    "    testset_list = args.dataset_folder[:-7] + \"wider_val.txt\"\n",
    "\n",
    "    with open(testset_list, 'r') as fr:\n",
    "        test_dataset = fr.read().split()\n",
    "    num_images = len(test_dataset)\n",
    "\n",
    "    _t = {'forward_pass': Timer(), 'misc': Timer()}\n",
    "\n",
    "    # testing begin\n",
    "    for i, img_name in enumerate(test_dataset):\n",
    "        image_path = testset_folder + img_name\n",
    "        img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        img = np.float32(img_raw)\n",
    "\n",
    "        # testing scale\n",
    "        target_size = 1600\n",
    "        max_size = 2150\n",
    "        im_shape = img.shape\n",
    "        im_size_min = np.min(im_shape[0:2])\n",
    "        im_size_max = np.max(im_shape[0:2])\n",
    "        resize = float(target_size) / float(im_size_min)\n",
    "        # prevent bigger axis from being more than max_size:\n",
    "        if np.round(resize * im_size_max) > max_size:\n",
    "            resize = float(max_size) / float(im_size_max)\n",
    "        if args.origin_size:\n",
    "            resize = 1\n",
    "\n",
    "        if resize != 1:\n",
    "            img = cv2.resize(img, None, None, fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
    "        im_height, im_width, _ = img.shape\n",
    "        scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "        img -= (104, 117, 123)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        scale = scale.to(device)\n",
    "\n",
    "        _t['forward_pass'].tic()\n",
    "        loc, conf, landms = net(img)  # forward pass\n",
    "        _t['forward_pass'].toc()\n",
    "        _t['misc'].tic()\n",
    "        priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "        priors = priorbox.forward()\n",
    "        priors = priors.to(device)\n",
    "        prior_data = priors.data\n",
    "        boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "        boxes = boxes * scale / resize\n",
    "        boxes = boxes.cpu().numpy()\n",
    "        scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "        landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "        scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                               img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                               img.shape[3], img.shape[2]])\n",
    "        scale1 = scale1.to(device)\n",
    "        landms = landms * scale1 / resize\n",
    "        landms = landms.cpu().numpy()\n",
    "\n",
    "        # ignore low scores\n",
    "        inds = np.where(scores > args.confidence_threshold)[0]\n",
    "        boxes = boxes[inds]\n",
    "        landms = landms[inds]\n",
    "        scores = scores[inds]\n",
    "\n",
    "        # keep top-K before NMS\n",
    "        order = scores.argsort()[::-1]\n",
    "        # order = scores.argsort()[::-1][:args.top_k]\n",
    "        boxes = boxes[order]\n",
    "        landms = landms[order]\n",
    "        scores = scores[order]\n",
    "\n",
    "        # do NMS\n",
    "        dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "        keep = py_cpu_nms(dets, args.nms_threshold)\n",
    "        # keep = nms(dets, args.nms_threshold,force_cpu=args.cpu)\n",
    "        dets = dets[keep, :]\n",
    "        landms = landms[keep]\n",
    "\n",
    "        # keep top-K faster NMS\n",
    "        # dets = dets[:args.keep_top_k, :]\n",
    "        # landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "        dets = np.concatenate((dets, landms), axis=1)\n",
    "        _t['misc'].toc()\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        save_name = args.save_folder + img_name[:-4] + \".txt\"\n",
    "        dirname = os.path.dirname(save_name)\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.makedirs(dirname)\n",
    "        with open(save_name, \"w\") as fd:\n",
    "            bboxs = dets\n",
    "            file_name = os.path.basename(save_name)[:-4] + \"\\n\"\n",
    "            bboxs_num = str(len(bboxs)) + \"\\n\"\n",
    "            fd.write(file_name)\n",
    "            fd.write(bboxs_num)\n",
    "            for box in bboxs:\n",
    "                x = int(box[0])\n",
    "                y = int(box[1])\n",
    "                w = int(box[2]) - int(box[0])\n",
    "                h = int(box[3]) - int(box[1])\n",
    "                confidence = str(box[4])\n",
    "                line = str(x) + \" \" + str(y) + \" \" + str(w) + \" \" + str(h) + \" \" + confidence + \" \\n\"\n",
    "                fd.write(line)\n",
    "\n",
    "        print('im_detect: {:d}/{:d} forward_pass_time: {:.4f}s misc: {:.4f}s'.format(i + 1, num_images, _t['forward_pass'].average_time, _t['misc'].average_time))\n",
    "\n",
    "        # save image\n",
    "        if args.save_image:\n",
    "            for b in dets:\n",
    "                if b[4] < args.vis_thres:\n",
    "                    continue\n",
    "                text = \"{:.4f}\".format(b[4])\n",
    "                b = list(map(int, b))\n",
    "                cv2.rectangle(img_raw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "                cx = b[0]\n",
    "                cy = b[1] + 12\n",
    "                cv2.putText(img_raw, text, (cx, cy),\n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255))\n",
    "\n",
    "                # landms\n",
    "                cv2.circle(img_raw, (b[5], b[6]), 1, (0, 0, 255), 4)\n",
    "                cv2.circle(img_raw, (b[7], b[8]), 1, (0, 255, 255), 4)\n",
    "                cv2.circle(img_raw, (b[9], b[10]), 1, (255, 0, 255), 4)\n",
    "                cv2.circle(img_raw, (b[11], b[12]), 1, (0, 255, 0), 4)\n",
    "                cv2.circle(img_raw, (b[13], b[14]), 1, (255, 0, 0), 4)\n",
    "            # save image\n",
    "            if not os.path.exists(\"./results/\"):\n",
    "                os.makedirs(\"./results/\")\n",
    "            name = \"./results/\" + str(i) + \".jpg\"\n",
    "            cv2.imwrite(name, img_raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
