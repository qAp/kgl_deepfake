{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp video_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# %load ../face_detection/video_utils.py\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def read_frame_as_size(video_path, size=(128, 128)):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, size)\n",
    "    capture.release()\n",
    "    return frame\n",
    "\n",
    "\n",
    "def read_frame(video_path):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    capture.release()\n",
    "    return frame\n",
    "\n",
    "\n",
    "def read_all_frames(video_path):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    all_frames = []\n",
    "    ret = True\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            all_frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    return np.array(all_frames)\n",
    "\n",
    "\n",
    "def read_frames(video_path, start=0, end=16):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    end = min(frame_count, end)\n",
    "\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "\n",
    "    frames = []\n",
    "    for i in range(start, end):\n",
    "        success, frame = capture.read()\n",
    "        if not success:\n",
    "            # If we couldn't read a frame, just continue\n",
    "            continue\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def read_all_frames_as_square_crops(video_path):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    all_frames = []\n",
    "    ret = True\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            all_frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "\n",
    "    all_frames = np.array(all_frames)\n",
    "\n",
    "    n_frames, height, width, channels = all_frames.shape\n",
    "\n",
    "    # For vertical videos, just take the square crop\n",
    "    if height > width:\n",
    "        all_frames = all_frames[:, :width, :, :]\n",
    "\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "def get_height_and_width_of_video(video_path):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "    height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "\n",
    "    return height, width\n",
    "\n",
    "\n",
    "def read_random_frames(video_path, num_frames=1):\n",
    "    \"\"\"\n",
    "    Read {num_frames} random frames from any point in the video.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        frame = read_random_frame(video_path)\n",
    "        frames.append(frame)\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def read_random_frame(video_path):\n",
    "    \"\"\"\n",
    "    Read a random frame from any point in the video.\n",
    "    \"\"\"\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # HACK: Some videos are missing the last 10 frames. No idea why.\n",
    "    random_frame = int(random.random() * frame_count) - 10\n",
    "    # Set to read specific frame\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, random_frame)\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    capture.release()\n",
    "    return frame\n",
    "\n",
    "\n",
    "def read_frame_at_frame_number(video_path, frame_number):\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    # Set to read specific frame\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    capture.release()\n",
    "    return frame\n",
    "\n",
    "\n",
    "def read_random_sequential_frames(video_path, num_frames=4):\n",
    "    \"\"\"\n",
    "    Starting at a random point in the video, read {num_frames} frames and return\n",
    "    as a single numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) - num_frames\n",
    "    random_frame = int(random.random() * frame_count)\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, random_frame)\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        # Set to read specific frame\n",
    "        ret, frame = capture.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "    capture.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def plot_detections(img, detections, with_keypoints=True, figsize=(10, 10)):\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\n",
    "    ax.grid(False)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    if isinstance(detections, torch.Tensor):\n",
    "        detections = detections.cpu().numpy()\n",
    "\n",
    "    print(\"Found %d faces\" % len(detections))\n",
    "\n",
    "    height, width, c = img.shape\n",
    "\n",
    "    for i in range(len(detections)):\n",
    "        xmin = max(0, detections[i, 0])\n",
    "        ymin = max(0, detections[i, 1])\n",
    "        xmax = min(width, detections[i, 2])\n",
    "        ymax = min(width, detections[i, 3])\n",
    "\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                 linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_video_stats(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return width, height, frame_rate, frame_num\n",
    "\n",
    "\n",
    "def nms(dets, thresh):\n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    scores = dets[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def load_all_metadata():\n",
    "    # Join metadata files into single dataframe\n",
    "    metadata_list = []\n",
    "\n",
    "    for i in tqdm(range(50)):\n",
    "        folder = Path(\"../data/dfdc_train_part_\" + str(i))\n",
    "        metadata_file_path = folder/'metadata.json'\n",
    "        metadata = pd.read_json(metadata_file_path).T\n",
    "\n",
    "        metadata.reset_index(inplace=True)\n",
    "        metadata.rename({'index' : 'fname'}, axis=1, inplace=True)\n",
    "\n",
    "        metadata['directory'] =  str(folder)\n",
    "\n",
    "        metadata_list.append(metadata)\n",
    "\n",
    "    all_metadata = pd.concat(metadata_list)\n",
    "    return all_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
