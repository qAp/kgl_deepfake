{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp pytorch_retinaface.utils.box_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# %load Pytorch_Retinaface/utils/box_utils.py\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def point_form(boxes):\n",
    "    \"\"\" Convert prior_boxes to (xmin, ymin, xmax, ymax)\n",
    "    representation for comparison to point form ground truth data.\n",
    "    Args:\n",
    "        boxes: (tensor) center-size default boxes from priorbox layers.\n",
    "    Return:\n",
    "        boxes: (tensor) Converted xmin, ymin, xmax, ymax form of boxes.\n",
    "    \"\"\"\n",
    "    return torch.cat((boxes[:, :2] - boxes[:, 2:]/2,     # xmin, ymin\n",
    "                     boxes[:, :2] + boxes[:, 2:]/2), 1)  # xmax, ymax\n",
    "\n",
    "\n",
    "def center_size(boxes):\n",
    "    \"\"\" Convert prior_boxes to (cx, cy, w, h)\n",
    "    representation for comparison to center-size form ground truth data.\n",
    "    Args:\n",
    "        boxes: (tensor) point_form boxes\n",
    "    Return:\n",
    "        boxes: (tensor) Converted xmin, ymin, xmax, ymax form of boxes.\n",
    "    \"\"\"\n",
    "    return torch.cat((boxes[:, 2:] + boxes[:, :2])/2,  # cx, cy\n",
    "                     boxes[:, 2:] - boxes[:, :2], 1)  # w, h\n",
    "\n",
    "\n",
    "def intersect(box_a, box_b):\n",
    "    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n",
    "    [A,2] -> [A,1,2] -> [A,B,2]\n",
    "    [B,2] -> [1,B,2] -> [A,B,2]\n",
    "    Then we compute the area of intersect between box_a and box_b.\n",
    "    Args:\n",
    "      box_a: (tensor) bounding boxes, Shape: [A,4].\n",
    "      box_b: (tensor) bounding boxes, Shape: [B,4].\n",
    "    Return:\n",
    "      (tensor) intersection area, Shape: [A,B].\n",
    "    \"\"\"\n",
    "    A = box_a.size(0)\n",
    "    B = box_b.size(0)\n",
    "    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n",
    "                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n",
    "    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n",
    "                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "\n",
    "def jaccard(box_a, box_b):\n",
    "    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n",
    "    is simply the intersection over union of two boxes.  Here we operate on\n",
    "    ground truth boxes and default boxes.\n",
    "    E.g.:\n",
    "        A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)\n",
    "    Args:\n",
    "        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n",
    "        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n",
    "    Return:\n",
    "        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n",
    "    \"\"\"\n",
    "    inter = intersect(box_a, box_b)\n",
    "    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n",
    "              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n",
    "    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n",
    "              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n",
    "    union = area_a + area_b - inter\n",
    "    return inter / union  # [A,B]\n",
    "\n",
    "\n",
    "def matrix_iou(a, b):\n",
    "    \"\"\"\n",
    "    return iou of a and b, numpy version for data augenmentation\n",
    "    \"\"\"\n",
    "    lt = np.maximum(a[:, np.newaxis, :2], b[:, :2])\n",
    "    rb = np.minimum(a[:, np.newaxis, 2:], b[:, 2:])\n",
    "\n",
    "    area_i = np.prod(rb - lt, axis=2) * (lt < rb).all(axis=2)\n",
    "    area_a = np.prod(a[:, 2:] - a[:, :2], axis=1)\n",
    "    area_b = np.prod(b[:, 2:] - b[:, :2], axis=1)\n",
    "    return area_i / (area_a[:, np.newaxis] + area_b - area_i)\n",
    "\n",
    "\n",
    "def matrix_iof(a, b):\n",
    "    \"\"\"\n",
    "    return iof of a and b, numpy version for data augenmentation\n",
    "    \"\"\"\n",
    "    lt = np.maximum(a[:, np.newaxis, :2], b[:, :2])\n",
    "    rb = np.minimum(a[:, np.newaxis, 2:], b[:, 2:])\n",
    "\n",
    "    area_i = np.prod(rb - lt, axis=2) * (lt < rb).all(axis=2)\n",
    "    area_a = np.prod(a[:, 2:] - a[:, :2], axis=1)\n",
    "    return area_i / np.maximum(area_a[:, np.newaxis], 1)\n",
    "\n",
    "\n",
    "def match(threshold, truths, priors, variances, labels, landms, loc_t, conf_t, landm_t, idx):\n",
    "    \"\"\"Match each prior box with the ground truth box of the highest jaccard\n",
    "    overlap, encode the bounding boxes, then return the matched indices\n",
    "    corresponding to both confidence and location preds.\n",
    "    Args:\n",
    "        threshold: (float) The overlap threshold used when mathing boxes.\n",
    "        truths: (tensor) Ground truth boxes, Shape: [num_obj, 4].\n",
    "        priors: (tensor) Prior boxes from priorbox layers, Shape: [n_priors,4].\n",
    "        variances: (tensor) Variances corresponding to each prior coord,\n",
    "            Shape: [num_priors, 4].\n",
    "        labels: (tensor) All the class labels for the image, Shape: [num_obj].\n",
    "        landms: (tensor) Ground truth landms, Shape [num_obj, 10].\n",
    "        loc_t: (tensor) Tensor to be filled w/ endcoded location targets.\n",
    "        conf_t: (tensor) Tensor to be filled w/ matched indices for conf preds.\n",
    "        landm_t: (tensor) Tensor to be filled w/ endcoded landm targets.\n",
    "        idx: (int) current batch index\n",
    "    Return:\n",
    "        The matched indices corresponding to 1)location 2)confidence 3)landm preds.\n",
    "    \"\"\"\n",
    "    # jaccard index\n",
    "    overlaps = jaccard(\n",
    "        truths,\n",
    "        point_form(priors)\n",
    "    )\n",
    "    # (Bipartite Matching)\n",
    "    # [1,num_objects] best prior for each ground truth\n",
    "    best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True)\n",
    "\n",
    "    # ignore hard gt\n",
    "    valid_gt_idx = best_prior_overlap[:, 0] >= 0.2\n",
    "    best_prior_idx_filter = best_prior_idx[valid_gt_idx, :]\n",
    "    if best_prior_idx_filter.shape[0] <= 0:\n",
    "        loc_t[idx] = 0\n",
    "        conf_t[idx] = 0\n",
    "        return\n",
    "\n",
    "    # [1,num_priors] best ground truth for each prior\n",
    "    best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True)\n",
    "    best_truth_idx.squeeze_(0)\n",
    "    best_truth_overlap.squeeze_(0)\n",
    "    best_prior_idx.squeeze_(1)\n",
    "    best_prior_idx_filter.squeeze_(1)\n",
    "    best_prior_overlap.squeeze_(1)\n",
    "    best_truth_overlap.index_fill_(0, best_prior_idx_filter, 2)  # ensure best prior\n",
    "    # TODO refactor: index  best_prior_idx with long tensor\n",
    "    # ensure every gt matches with its prior of max overlap\n",
    "    for j in range(best_prior_idx.size(0)):     # 判别此anchor是预测哪一个boxes\n",
    "        best_truth_idx[best_prior_idx[j]] = j\n",
    "    matches = truths[best_truth_idx]            # Shape: [num_priors,4] 此处为每一个anchor对应的bbox取出来\n",
    "    conf = labels[best_truth_idx]               # Shape: [num_priors]      此处为每一个anchor对应的label取出来\n",
    "    conf[best_truth_overlap < threshold] = 0    # label as background   overlap<0.35的全部作为负样本\n",
    "    loc = encode(matches, priors, variances)\n",
    "\n",
    "    matches_landm = landms[best_truth_idx]\n",
    "    landm = encode_landm(matches_landm, priors, variances)\n",
    "    loc_t[idx] = loc    # [num_priors,4] encoded offsets to learn\n",
    "    conf_t[idx] = conf  # [num_priors] top class label for each prior\n",
    "    landm_t[idx] = landm\n",
    "\n",
    "\n",
    "def encode(matched, priors, variances):\n",
    "    \"\"\"Encode the variances from the priorbox layers into the ground truth boxes\n",
    "    we have matched (based on jaccard overlap) with the prior boxes.\n",
    "    Args:\n",
    "        matched: (tensor) Coords of ground truth for each prior in point-form\n",
    "            Shape: [num_priors, 4].\n",
    "        priors: (tensor) Prior boxes in center-offset form\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        encoded boxes (tensor), Shape: [num_priors, 4]\n",
    "    \"\"\"\n",
    "\n",
    "    # dist b/t match center and prior's center\n",
    "    g_cxcy = (matched[:, :2] + matched[:, 2:])/2 - priors[:, :2]\n",
    "    # encode variance\n",
    "    g_cxcy /= (variances[0] * priors[:, 2:])\n",
    "    # match wh / prior wh\n",
    "    g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:]\n",
    "    g_wh = torch.log(g_wh) / variances[1]\n",
    "    # return target for smooth_l1_loss\n",
    "    return torch.cat([g_cxcy, g_wh], 1)  # [num_priors,4]\n",
    "\n",
    "def encode_landm(matched, priors, variances):\n",
    "    \"\"\"Encode the variances from the priorbox layers into the ground truth boxes\n",
    "    we have matched (based on jaccard overlap) with the prior boxes.\n",
    "    Args:\n",
    "        matched: (tensor) Coords of ground truth for each prior in point-form\n",
    "            Shape: [num_priors, 10].\n",
    "        priors: (tensor) Prior boxes in center-offset form\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        encoded landm (tensor), Shape: [num_priors, 10]\n",
    "    \"\"\"\n",
    "\n",
    "    # dist b/t match center and prior's center\n",
    "    matched = torch.reshape(matched, (matched.size(0), 5, 2))\n",
    "    priors_cx = priors[:, 0].unsqueeze(1).expand(matched.size(0), 5).unsqueeze(2)\n",
    "    priors_cy = priors[:, 1].unsqueeze(1).expand(matched.size(0), 5).unsqueeze(2)\n",
    "    priors_w = priors[:, 2].unsqueeze(1).expand(matched.size(0), 5).unsqueeze(2)\n",
    "    priors_h = priors[:, 3].unsqueeze(1).expand(matched.size(0), 5).unsqueeze(2)\n",
    "    priors = torch.cat([priors_cx, priors_cy, priors_w, priors_h], dim=2)\n",
    "    g_cxcy = matched[:, :, :2] - priors[:, :, :2]\n",
    "    # encode variance\n",
    "    g_cxcy /= (variances[0] * priors[:, :, 2:])\n",
    "    # g_cxcy /= priors[:, :, 2:]\n",
    "    g_cxcy = g_cxcy.reshape(g_cxcy.size(0), -1)\n",
    "    # return target for smooth_l1_loss\n",
    "    return g_cxcy\n",
    "\n",
    "\n",
    "# Adapted from https://github.com/Hakuyume/chainer-ssd\n",
    "def decode(loc, priors, variances):\n",
    "    \"\"\"Decode locations from predictions using priors to undo\n",
    "    the encoding we did for offset regression at train time.\n",
    "    Args:\n",
    "        loc (tensor): location predictions for loc layers,\n",
    "            Shape: [num_priors,4]\n",
    "        priors (tensor): Prior boxes in center-offset form.\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        decoded bounding box predictions\n",
    "    \"\"\"\n",
    "\n",
    "    boxes = torch.cat((\n",
    "        priors[:, :2] + loc[:, :2] * variances[0] * priors[:, 2:],\n",
    "        priors[:, 2:] * torch.exp(loc[:, 2:] * variances[1])), 1)\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2\n",
    "    boxes[:, 2:] += boxes[:, :2]\n",
    "    return boxes\n",
    "\n",
    "def decode_landm(pre, priors, variances):\n",
    "    \"\"\"Decode landm from predictions using priors to undo\n",
    "    the encoding we did for offset regression at train time.\n",
    "    Args:\n",
    "        pre (tensor): landm predictions for loc layers,\n",
    "            Shape: [num_priors,10]\n",
    "        priors (tensor): Prior boxes in center-offset form.\n",
    "            Shape: [num_priors,4].\n",
    "        variances: (list[float]) Variances of priorboxes\n",
    "    Return:\n",
    "        decoded landm predictions\n",
    "    \"\"\"\n",
    "    landms = torch.cat((priors[:, :2] + pre[:, :2] * variances[0] * priors[:, 2:],\n",
    "                        priors[:, :2] + pre[:, 2:4] * variances[0] * priors[:, 2:],\n",
    "                        priors[:, :2] + pre[:, 4:6] * variances[0] * priors[:, 2:],\n",
    "                        priors[:, :2] + pre[:, 6:8] * variances[0] * priors[:, 2:],\n",
    "                        priors[:, :2] + pre[:, 8:10] * variances[0] * priors[:, 2:],\n",
    "                        ), dim=1)\n",
    "    return landms\n",
    "\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    \"\"\"Utility function for computing log_sum_exp while determining\n",
    "    This will be used to determine unaveraged confidence loss across\n",
    "    all examples in a batch.\n",
    "    Args:\n",
    "        x (Variable(tensor)): conf_preds from conf layers\n",
    "    \"\"\"\n",
    "    x_max = x.data.max()\n",
    "    return torch.log(torch.sum(torch.exp(x-x_max), 1, keepdim=True)) + x_max\n",
    "\n",
    "\n",
    "# Original author: Francisco Massa:\n",
    "# https://github.com/fmassa/object-detection.torch\n",
    "# Ported to PyTorch by Max deGroot (02/01/2017)\n",
    "def nms(boxes, scores, overlap=0.5, top_k=200):\n",
    "    \"\"\"Apply non-maximum suppression at test time to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].\n",
    "        scores: (tensor) The class predscores for the img, Shape:[num_priors].\n",
    "        overlap: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "        top_k: (int) The Maximum number of box preds to consider.\n",
    "    Return:\n",
    "        The indices of the kept boxes with respect to num_priors.\n",
    "    \"\"\"\n",
    "\n",
    "    keep = torch.Tensor(scores.size(0)).fill_(0).long()\n",
    "    if boxes.numel() == 0:\n",
    "        return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    # I = I[v >= 0.01]\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    # keep = torch.Tensor()\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        # keep.append(i)\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
