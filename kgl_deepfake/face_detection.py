# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_face_detection.ipynb (unless otherwise specified).

__all__ = ['DetectionPipeline', 'get_first_face', 'VideoFaceList']

# Cell
from IPython.display import HTML
import cv2
from fastai.core import *
from fastai.vision import *
from facenet_pytorch import MTCNN
from .nb_00 import *

# Cell
class DetectionPipeline:
    def __init__(self, detector=None, nf=None, bs=60, fsz=None):
        if detector is None: detector = self.default_detector()
        self.detector = detector
        self.nf, self.bs, self.fsz = nf, bs, fsz

    def default_detector(self):
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        return MTCNN(device=device, image_size=256,
                     post_process=False, select_largest=False, keep_all=True)

    def get_sample(self, vlen, n_frames):
        if n_frames is None: return np.arange(0, vlen)
        else: return np.linspace(0, vlen - 1, n_frames).astype(int)

    def resize(self, frame, size):
        return frame.resize([int(d * size) for d in frame.size])

    def get_savepaths(self, filename, idxs, label=None, save_dir=None):
        if isinstance(filename, str): filename = Path(filename)
        if save_dir is None: save_dir = Path('./')
        if label is None: save_paths = [save_dir/f'{filename.stem}_{i:03d}.png' for i in idxs]
        else: save_paths = [save_dir/f'{filename.stem}_{i:03d}_{label}.png' for i in idxs]
        return [str(o) for o in save_paths]

    def __call__(self, filename, label=None, save_dir=None):
        assert Path(filename).exists()
        vcap = cv2.VideoCapture(str(filename))
        vlen = int(vcap.get(cv2.CAP_PROP_FRAME_COUNT))
        sample = self.get_sample(vlen, self.nf)
        iframes, faces, probs = [], [], []
        ib, fb = [], []
        for i in progress_bar(range(vlen)):
            _ = vcap.grab()
            if i in sample:
                success, f = vcap.retrieve()
                if not success: continue
                f = PIL.Image.fromarray(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))
                if self.fsz is not None: f = self.resize(f, self.fsz)
                ib.append(i); fb.append(f)
                if len(fb) % self.bs == 0 or i == sample[-1]:
                    savepaths = self.get_savepaths(filename, ib, label, save_dir) if save_dir else None
                    faceb, probb = self.detector(fb, return_prob=True, save_path=savepaths)
                    iframes.extend(ib); faces.extend(faceb); probs.extend(probb)
                    ib, fb = [], []
        vcap.release()
        return iframes, faces, probs

# Cell
def get_first_face(detector, fn, resize=.5, equalize=False):
    '''
    Returns the first detected face from a video
    '''
    assert Path(fn).exists()
    v_cap = cv2.VideoCapture(str(fn))
    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))
    iframe, face = None, None
    for i in range(v_len):
        _ = v_cap.grab()
        success, frame = v_cap.retrieve()
        if not success: continue
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)
        if equalize:
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            frame[:,:,0] = clahe.apply(frame[:,:,0])
        frame = cv2.cvtColor(frame, cv2.COLOR_YCrCb2RGB)
        frame = PIL.Image.fromarray(frame)
        if resize is not None: frame = frame.resize([int(d * resize) for d in frame.size])
        face = detector(frame)
        if face is not None:
            iframe = i
            break
    v_cap.release()
    return iframe, face

# Cell
class VideoFaceList(ImageList):
    def __init__(self, *args, detector=None, device=None, resize=.5, equalize=True, **kwargs):
        super().__init__(*args, **kwargs)
        if device is None: device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
        if detector is None: detector = MTCNN(device=device, post_process=False, select_largest=False, margin=0)
        self.detector, self.resize, self.equalize = detector, resize, equalize
        self.copy_new.extend(['detector', 'resize', 'equalize'])

    def get_face(self, fn:Path):
        iframe, face = get_first_face(self.detector, fn, self.resize, self.equalize)
        if iframe is None or face is None: raise Exception(f'No faces detected in {fn}')
        return iframe, face

    def open(self, fn:Path):
        iframe, face = self.get_face(fn)
        return Image(face / 255)