{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Raw Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated a number of predictions and now we would like to investigate different ways of distilling multiple frame predictions into a single video prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EasyRetinaFace import EasyRetinaFace\n",
    "from video_utils import read_frame, plot_detections\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from pathlib import Path\n",
    "from video_utils import load_all_metadata\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9994698 , 0.99946517, 0.99999034, 0.99983704, 0.9987105 ,\n",
       "       0.99988353, 0.9967527 , 0.9996308 , 0.9996635 , 0.9999956 ,\n",
       "       0.99808395, 0.9831117 , 0.9999862 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds = np.load('raw_preds.npy', allow_pickle=True).item()\n",
    "\n",
    "# Example\n",
    "first_key = list(raw_preds.keys())[0]\n",
    "raw_preds[first_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6977582e8b604a99a8649912d6519b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_metadata= load_all_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This competition's [evaluation metric](https://www.kaggle.com/c/deepfake-detection-challenge/overview/evaluation) is log loss which is given as:\n",
    "\n",
    "$\\textrm{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right]$\n",
    "\n",
    "We'll use sklearn's `log_loss()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577101277717478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate sample values\n",
    "y_true = []\n",
    "y_hat = []\n",
    "for i in range(10):\n",
    "    y_true.append(np.random.randint(2)) # int of 0 or 1\n",
    "    y_hat.append(np.random.rand())      # float between 0 and 1\n",
    "\n",
    "# Get loss with sklearn\n",
    "log_loss(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious and straightforward approach might be to simply average all of our raw predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder 0 0.5327780385038207\n",
      "folder 1 0.5944749533284013\n",
      "folder 2 0.6016714495100052\n",
      "all 0.5844726400986539\n"
     ]
    }
   ],
   "source": [
    "# Keep track of predictions for each folder\n",
    "folder_0_avg_preds = []\n",
    "folder_0_y_true = []\n",
    "\n",
    "folder_1_avg_preds = []\n",
    "folder_1_y_true = []\n",
    "\n",
    "folder_2_avg_preds = []\n",
    "folder_2_y_true = []\n",
    "\n",
    "for path, preds in raw_preds.items():\n",
    "    # Note that we clip values\n",
    "    avg = np.mean(preds).clip(0.01, 0.99)\n",
    "\n",
    "    row = all_metadata.loc[all_metadata['fname'] == path].iloc[0]\n",
    "    \n",
    "    if row['directory'] == '../data/dfdc_train_part_0':\n",
    "        y_true = folder_0_y_true\n",
    "        avg_preds = folder_0_avg_preds\n",
    "    elif row['directory'] == '../data/dfdc_train_part_1':\n",
    "        y_true = folder_1_y_true\n",
    "        avg_preds = folder_1_avg_preds\n",
    "    elif row['directory'] == '../data/dfdc_train_part_2':\n",
    "        y_true = folder_2_y_true\n",
    "        avg_preds = folder_2_avg_preds\n",
    "    else:\n",
    "        raise Exception(\"Invalid entry\")\n",
    "    \n",
    "    avg_preds.append(avg)\n",
    "    y = 1 if row['label'] == 'FAKE' else 0\n",
    "    y_true.append(y)\n",
    "    \n",
    "print(\"folder 0\", log_loss(folder_0_y_true, folder_0_avg_preds))\n",
    "print(\"folder 1\", log_loss(folder_1_y_true, folder_1_avg_preds))\n",
    "print(\"folder 2\", log_loss(folder_2_y_true, folder_2_avg_preds))\n",
    "\n",
    "all_true = folder_0_y_true + folder_1_y_true + folder_2_y_true\n",
    "all_preds = folder_0_avg_preds + folder_1_avg_preds + folder_2_avg_preds\n",
    "print(\"all\", log_loss(all_true, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Max Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a single frame is enough evidence that we've encountered a deep fake. Let's try taking the max value and what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6531126914403507"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = []\n",
    "y_true = []\n",
    "\n",
    "for path, preds in raw_preds.items():\n",
    "    # Note that we clip values\n",
    "    avg = np.max(preds).clip(0.01, 0.99)\n",
    "    avg_preds.append(avg)\n",
    "    \n",
    "    y = 1 if all_metadata.loc[all_metadata['fname'] == path]['label'].iloc[0] == 'FAKE' else 0\n",
    "    y_true.append(y)\n",
    "    \n",
    "log_loss(y_true, avg_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
