{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D + 2D Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much to my disappointment, I wasn't able to get 3D convolutions to perform very well on our data. It's possible that I should have used a larger dataset or I implemented something incorrectly. Either way, let's try a new approach:\n",
    "\n",
    "1D + 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from fastai.core import *\n",
    "from fastai.vision import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../data/hard_video_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_video_frames_as_image(self, filename):\n",
    "    # Open frames\n",
    "    frames = np.load(filename)\n",
    "        \n",
    "    # Convert to tensor and normalize\n",
    "    frames_tensor = torch.from_numpy(frames).float()\n",
    "    frames_tensor.div_(255)\n",
    "    \n",
    "    frames_tensor = frames_tensor.permute(2, 0, 1)\n",
    "    \n",
    "    return Image(frames_tensor)\n",
    "    \n",
    "ImageList.open = open_video_frames_as_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemLists;\n",
       "\n",
       "Train: ImageList (799 items)\n",
       "Image (48, 164, 149),Image (48, 211, 206),Image (48, 277, 289),Image (48, 250, 241),Image (48, 237, 251)\n",
       "Path: ../data/hard_video_frames;\n",
       "\n",
       "Valid: ImageList (200 items)\n",
       "Image (48, 255, 240),Image (48, 231, 230),Image (48, 239, 241),Image (48, 219, 236),Image (48, 108, 87)\n",
       "Path: ../data/hard_video_frames;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = ImageList.from_folder(path, extensions='.npy').split_by_folder(train='train', valid='val')\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_re('([A-Z]+).npy$')\n",
    "           .transform(get_transforms(max_warp=0, max_zoom=1), size=size)\n",
    "           .databunch(bs=bs))\n",
    "    #TODO: Normalize somehow\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, sz = 8, 128\n",
    "data = get_data(bs, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import _triple\n",
    "\n",
    "\n",
    "class SpatioTemporalConv(nn.Module):\n",
    "    r\"\"\"Applies a factored 3D convolution over an input signal composed of several input \n",
    "    planes with distinct spatial and time axes, by performing a 2D convolution over the \n",
    "    spatial axes to an intermediate subspace, followed by a 1D convolution over the time \n",
    "    axis to produce the final output.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input tensor\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int or tuple, optional): Zero-padding added to the sides of the input during their respective convolutions. Default: 0\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
    "        super(SpatioTemporalConv, self).__init__()\n",
    "\n",
    "        # if ints are entered, convert them to iterables, 1 -> [1, 1, 1]\n",
    "        kernel_size = _triple(kernel_size)\n",
    "        stride = _triple(stride)\n",
    "        padding = _triple(padding)\n",
    "\n",
    "        # decomposing the parameters into spatial and temporal components by\n",
    "        # masking out the values with the defaults on the axis that\n",
    "        # won't be convolved over. This is necessary to avoid unintentional\n",
    "        # behavior such as padding being added twice\n",
    "        spatial_kernel_size =  [1, kernel_size[1], kernel_size[2]]\n",
    "        spatial_stride =  [1, stride[1], stride[2]]\n",
    "        spatial_padding =  [0, padding[1], padding[2]]\n",
    "\n",
    "        temporal_kernel_size = [kernel_size[0], 1, 1]\n",
    "        temporal_stride =  [stride[0], 1, 1]\n",
    "        temporal_padding =  [padding[0], 0, 0]\n",
    "\n",
    "        # compute the number of intermediary channels (M) using formula \n",
    "        # from the paper section 3.5\n",
    "        intermed_channels = int(math.floor((kernel_size[0] * kernel_size[1] * kernel_size[2] * in_channels * out_channels)/ \\\n",
    "                            (kernel_size[1]* kernel_size[2] * in_channels + kernel_size[0] * out_channels)))\n",
    "\n",
    "        # the spatial conv is effectively a 2D conv due to the \n",
    "        # spatial_kernel_size, followed by batch_norm and ReLU\n",
    "        self.spatial_conv = nn.Conv3d(in_channels, intermed_channels, spatial_kernel_size,\n",
    "                                    stride=spatial_stride, padding=spatial_padding, bias=bias)\n",
    "        self.bn = nn.BatchNorm3d(intermed_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # the temporal conv is effectively a 1D conv, but has batch norm \n",
    "        # and ReLU added inside the model constructor, not here. This is an \n",
    "        # intentional design choice, to allow this module to externally act \n",
    "        # identical to a standard Conv3D, so it can be reused easily in any \n",
    "        # other codebase\n",
    "        self.temporal_conv = nn.Conv3d(intermed_channels, out_channels, temporal_kernel_size, \n",
    "                                    stride=temporal_stride, padding=temporal_padding, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.spatial_conv(x)))\n",
    "        x = self.temporal_conv(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import _triple\n",
    "\n",
    "\n",
    "class SpatioTemporalResBlock(nn.Module):\n",
    "    r\"\"\"Single block for the ResNet network. Uses SpatioTemporalConv in \n",
    "        the standard ResNet block layout (conv->batchnorm->ReLU->conv->batchnorm->sum->ReLU)\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input tensor.\n",
    "            out_channels (int): Number of channels in the output produced by the block.\n",
    "            kernel_size (int or tuple): Size of the convolving kernels.\n",
    "            downsample (bool, optional): If ``True``, the output size is to be smaller than the input. Default: ``False``\n",
    "        \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, downsample=False):\n",
    "        super(SpatioTemporalResBlock, self).__init__()\n",
    "        \n",
    "        # If downsample == True, the first conv of the layer has stride = 2 \n",
    "        # to halve the residual output size, and the input x is passed \n",
    "        # through a seperate 1x1x1 conv with stride = 2 to also halve it.\n",
    "\n",
    "        # no pooling layers are used inside ResNet\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        # to allow for SAME padding\n",
    "        padding = kernel_size//2\n",
    "\n",
    "        if self.downsample:\n",
    "            # downsample with stride =2 the input x\n",
    "            self.downsampleconv = SpatioTemporalConv(in_channels, out_channels, 1, stride=2)\n",
    "            self.downsamplebn = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "            # downsample with stride = 2when producing the residual\n",
    "            self.conv1 = SpatioTemporalConv(in_channels, out_channels, kernel_size, padding=padding, stride=2)\n",
    "        else:\n",
    "            self.conv1 = SpatioTemporalConv(in_channels, out_channels, kernel_size, padding=padding)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # standard conv->batchnorm->ReLU\n",
    "        self.conv2 = SpatioTemporalConv(out_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.outrelu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.relu1(self.bn1(self.conv1(x)))    \n",
    "        res = self.bn2(self.conv2(res))\n",
    "\n",
    "        if self.downsample:\n",
    "            x = self.downsamplebn(self.downsampleconv(x))\n",
    "\n",
    "        return self.outrelu(x + res)\n",
    "\n",
    "\n",
    "class SpatioTemporalResLayer(nn.Module):\n",
    "    r\"\"\"Forms a single layer of the ResNet network, with a number of repeating \n",
    "    blocks of same output size stacked on top of each other\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input tensor.\n",
    "            out_channels (int): Number of channels in the output produced by the layer.\n",
    "            kernel_size (int or tuple): Size of the convolving kernels.\n",
    "            layer_size (int): Number of blocks to be stacked to form the layer\n",
    "            block_type (Module, optional): Type of block that is to be used to form the layer. Default: SpatioTemporalResBlock. \n",
    "            downsample (bool, optional): If ``True``, the first block in layer will implement downsampling. Default: ``False``\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, layer_size, block_type=SpatioTemporalResBlock, downsample=False):\n",
    "        \n",
    "        super(SpatioTemporalResLayer, self).__init__()\n",
    "\n",
    "        # implement the first block\n",
    "        self.block1 = block_type(in_channels, out_channels, kernel_size, downsample)\n",
    "\n",
    "        # prepare module list to hold all (layer_size - 1) blocks\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for i in range(layer_size - 1):\n",
    "            # all these blocks are identical, and have downsample = False by default\n",
    "            self.blocks += [block_type(out_channels, out_channels, kernel_size)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class R2Plus1DNet(nn.Module):\n",
    "    r\"\"\"Forms the overall ResNet feature extractor by initializng 5 layers, with the number of blocks in \n",
    "    each layer set by layer_sizes, and by performing a global average pool at the end producing a \n",
    "    512-dimensional vector for each element in the batch.\n",
    "        \n",
    "        Args:\n",
    "            layer_sizes (tuple): An iterable containing the number of blocks in each layer\n",
    "            block_type (Module, optional): Type of block that is to be used to form the layers. Default: SpatioTemporalResBlock. \n",
    "        \"\"\"\n",
    "    def __init__(self, layer_sizes, block_type=SpatioTemporalResBlock):\n",
    "        super(R2Plus1DNet, self).__init__()\n",
    "\n",
    "        # first conv, with stride 1x2x2 and kernel size 3x7x7\n",
    "        self.conv1 = SpatioTemporalConv(3, 64, [3, 7, 7], stride=[1, 2, 2], padding=[1, 3, 3])\n",
    "        # output of conv2 is same size as of conv1, no downsampling needed. kernel_size 3x3x3\n",
    "        self.conv2 = SpatioTemporalResLayer(64, 64, 3, layer_sizes[0], block_type=block_type)\n",
    "        # each of the final three layers doubles num_channels, while performing downsampling \n",
    "        # inside the first block\n",
    "        self.conv3 = SpatioTemporalResLayer(64, 128, 3, layer_sizes[1], block_type=block_type, downsample=True)\n",
    "        self.conv4 = SpatioTemporalResLayer(128, 256, 3, layer_sizes[2], block_type=block_type, downsample=True)\n",
    "        self.conv5 = SpatioTemporalResLayer(256, 512, 3, layer_sizes[3], block_type=block_type, downsample=True)\n",
    "\n",
    "        # global average pooling of the output\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Reshape inputs\n",
    "        x = x.reshape(bs, 16, 3, sz, sz).permute(0, 2, 1, 3, 4)\n",
    "        x = x.cuda()\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        return x.view(-1, 512)\n",
    "\n",
    "class R2Plus1DClassifier(nn.Module):\n",
    "    r\"\"\"Forms a complete ResNet classifier producing vectors of size num_classes, by initializng 5 layers, \n",
    "    with the number of blocks in each layer set by layer_sizes, and by performing a global average pool\n",
    "    at the end producing a 512-dimensional vector for each element in the batch, \n",
    "    and passing them through a Linear layer.\n",
    "        \n",
    "        Args:\n",
    "            num_classes(int): Number of classes in the data\n",
    "            layer_sizes (tuple): An iterable containing the number of blocks in each layer\n",
    "            block_type (Module, optional): Type of block that is to be used to form the layers. Default: SpatioTemporalResBlock. \n",
    "        \"\"\"\n",
    "    def __init__(self, num_classes, layer_sizes, block_type=SpatioTemporalResBlock):\n",
    "        super(R2Plus1DClassifier, self).__init__()\n",
    "\n",
    "        self.res2plus1d = R2Plus1DNet(layer_sizes, block_type)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res2plus1d(x)\n",
    "        x = self.linear(x) \n",
    "\n",
    "        return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = R2Plus1DClassifier(num_classes=2, layer_sizes=[2, 2, 2, 2])\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33192736"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learner and group parameters \n",
    "learner = Learner(data, model, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='96' class='' max='99', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      96.97% [96/99 01:19<00:02 1.2954]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.700502</td>\n",
       "      <td>0.692656</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.710197</td>\n",
       "      <td>0.698418</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710076</td>\n",
       "      <td>0.723940</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.710508</td>\n",
       "      <td>0.804434</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.724642</td>\n",
       "      <td>0.710988</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>0.704859</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>0.742768</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.708882</td>\n",
       "      <td>0.709511</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.706040</td>\n",
       "      <td>0.699667</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.709146</td>\n",
       "      <td>0.702660</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.704186</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.703594</td>\n",
       "      <td>0.721653</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.705125</td>\n",
       "      <td>0.697275</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.700418</td>\n",
       "      <td>0.699267</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.697009</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.694802</td>\n",
       "      <td>0.703533</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.694865</td>\n",
       "      <td>0.694077</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.693443</td>\n",
       "      <td>0.694541</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.692981</td>\n",
       "      <td>0.694153</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.689220</td>\n",
       "      <td>0.694605</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(20, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      30.00% [6/20 08:18<19:22]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.688949</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696882</td>\n",
       "      <td>0.695273</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.698691</td>\n",
       "      <td>0.707367</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.703560</td>\n",
       "      <td>0.729542</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.704276</td>\n",
       "      <td>0.706857</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.700763</td>\n",
       "      <td>0.707648</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='86' class='' max='99', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      86.87% [86/99 01:05<00:09 0.6983]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-650ff2f83ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(20, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
